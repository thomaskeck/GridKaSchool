{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Level Tensorflow API\n",
    "\n",
    "This exercise introduces the low-level concepts and API of tensorflow.\n",
    "You will learn the following concepts\n",
    "  - basic tensorflow objects: tensor, operation, graph and session\n",
    "  - automatic differentiation\n",
    "  - multi-class classification (on MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workshop_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy\n",
    "\n",
    "I assume you are familiare with the **numpy** package.\n",
    "If you execute numpy code the **numeric calculations** are done immediately.\n",
    "So if we multiply a vector with a matrix we immediately get the result:\n",
    "\n",
    "$$ \\vec{y} = W \\cdot \\vec{x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\vec{y} = \\begin{bmatrix}\n",
       "  1. & 2. & 3.\\\\\n",
       "\\end{bmatrix} \\cdot \\begin{bmatrix}\n",
       "  4. & 5.\\\\\n",
       "  6. & 7.\\\\\n",
       "  8. & 9.\\\\\n",
       "\\end{bmatrix} = \\begin{bmatrix}\n",
       "  40. & 46.\\\\\n",
       "\\end{bmatrix}$$"
      ],
      "text/plain": [
       "<workshop_utils.NumpyToLatex at 0x7f112cffc4a8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1.0, 2.0, 3.0]])\n",
    "W = np.array([[4.0, 5.0], [6.0, 7.0], [8.0, 9.0]])\n",
    "y = np.matmul(x, W)\n",
    "NumpyToLatex(r\"\\vec{y} = x \\cdot W = y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief NumPy Summary\n",
    "\n",
    "A brief summary of the most basic concepts of numpy.\n",
    "\n",
    "#### `np.ndarrays`\n",
    "Numpy heavily builds on the `np.ndarray` class (**n-dimensional arrays**).\n",
    "An `np.ndarray` consists of:\n",
    "  - a data-type (**dtype**);\n",
    "  - a dimension (**shape**);\n",
    "  - and its stored values.\n",
    "\n",
    "https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.ndarray.html\n",
    "\n",
    "#### `np.ufunc`\n",
    "Most numpy calculations can be understood in form of `np.ndarray` which are transformed by `np.ufunc`s (universal functions).\n",
    "\n",
    "A `np.ufunc` operates on an `np.ndarray` in an element-by-element fashion\n",
    "  * A fixed number of scalar inputs is mapped on a fixed number of scalar outputs\n",
    "  * Supports vectorization\n",
    "  * Usually implemented in C\n",
    "\n",
    "https://docs.scipy.org/doc/numpy-1.14.0/reference/ufuncs.html\n",
    "\n",
    "#### broadcasting\n",
    "\n",
    "If you operate with a `np.ufunc` on `np.ndarrays` with different shapes, numpy will broadcast them for you.\n",
    "\n",
    " https://docs.scipy.org/doc/numpy-1.10.0/user/basics.broadcasting.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow\n",
    "\n",
    "Tensorflow code looks at its core very similar to numpy, but instead of immediately calculating the result,\n",
    "tensorflow builds a **symbolic representation** of your calculation called a **graph**.\n",
    "This graph is then later executed on your CPU, GPU, or even distributed over several servers.\n",
    "\n",
    "#### `np.ndarray` $\\rightarrow$ `tf.Tensor`\n",
    "\n",
    "Instead of np.ndarray objects, tensorflow builds on `tf.Tensor` objects.\n",
    "A tensor represents an n-dimensional array with a **dtype**, a **shape** and a **name**.\n",
    "But the shape can be partly unspecified (e.g. shape=[None, 3] would be a matrix with 3 columns and an unspecified number of rows). You input data, the output and the parameter of your neural networks, everything will be represented by a tf.Tensor.\n",
    "\n",
    "https://www.tensorflow.org/programmers_guide/tensors\n",
    "\n",
    "#### `np.ufunc` $\\rightarrow$ `tf.Operation`\n",
    "\n",
    "Every function you apply to a `tf.Tensor` will be represented as a `tf.Operation` in a `tf.Graph`.\n",
    "A operation takes zero or more `tf.Tensor`s and outputs zero or more `tf.Tensor`s.\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.Graph`\n",
    "\n",
    "Let us build our first `tf.Graph`. Actually you don't have to create a `tf.Graph`, there is a default graph automatically created by tensorflow. We just wrap the numpy ndarrays defined above in `tf.Tensor` objects (here we use tf.constant). We apply the matrix multiplication operation to our tensors, and visualize the resulting graph.\n",
    "**Remember**: We did not calculate anything yet, we just defined the calculation in a symbolic way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"134pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 134.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 130,-112 130,4 -4,4\"/>\n",
       "<!-- MatMul -->\n",
       "<g id=\"node1\" class=\"node\"><title>MatMul</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"40.0939\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">MatMul</text>\n",
       "</g>\n",
       "<!-- x -->\n",
       "<g id=\"node2\" class=\"node\"><title>x</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">x</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;MatMul -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>x&#45;&gt;MatMul</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.3496,-72.7646C39.6492,-64.4043 44.9918,-54.0159 49.8312,-44.6059\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"52.9847,-46.127 54.4457,-35.6334 46.7596,-42.9256 52.9847,-46.127\"/>\n",
       "</g>\n",
       "<!-- W -->\n",
       "<g id=\"node3\" class=\"node\"><title>W</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">W</text>\n",
       "</g>\n",
       "<!-- W&#45;&gt;MatMul -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>W&#45;&gt;MatMul</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.6504,-72.7646C86.3508,-64.4043 81.0082,-54.0159 76.1688,-44.6059\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.2404,-42.9256 71.5543,-35.6334 73.0153,-46.127 79.2404,-42.9256\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<workshop_utils.TensorflowGraphToDot at 0x7f111a067e80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x_symbol = tf.constant(x, name='x')\n",
    "W_symbol = tf.constant(W, name='W')\n",
    "y_symbol = tf.matmul(x_symbol, W_symbol)\n",
    "TensorflowGraphToDot(y_symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "You can think of the **nodes** of the graphs as the operations, and the **connections** of the graph as the **tensors flowing** in and out of the operations.\n",
    "\n",
    "Hence the name: **tensorflow**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Differentiation\n",
    "\n",
    "Representing your calculation as a graph has many advantages. An important one is that we can perform symbolic calculations on the graph. For instance, tensorflow can automatically differentiate a graph with respect to one of its constituents.\n",
    "The result will be another graph, which calculates the gradients.\n",
    "\n",
    "For the training of arbitrary neural networks this is a huge advantage, because we only have to implement the forward pass of the neural network, and the necessary calculations for the backpropagation can be automatically generated by tensorflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"336pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 336.33 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-184 332.333,-184 332.333,4 -4,4\"/>\n",
       "<!-- gradients/MatMul_grad/MatMul -->\n",
       "<g id=\"node1\" class=\"node\"><title>gradients/MatMul_grad/MatMul</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"200.944\" cy=\"-18\" rx=\"127.277\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.944\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">gradients/MatMul_grad/MatMul</text>\n",
       "</g>\n",
       "<!-- gradients/Fill -->\n",
       "<g id=\"node2\" class=\"node\"><title>gradients/Fill</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"149.944\" cy=\"-90\" rx=\"57.6901\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.944\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">gradients/Fill</text>\n",
       "</g>\n",
       "<!-- gradients/Fill&#45;&gt;gradients/MatMul_grad/MatMul -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>gradients/Fill&#45;&gt;gradients/MatMul_grad/MatMul</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M162.29,-72.055C168.339,-63.7526 175.747,-53.5837 182.454,-44.3778\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"185.298,-46.4187 188.358,-36.2753 179.64,-42.2967 185.298,-46.4187\"/>\n",
       "</g>\n",
       "<!-- W -->\n",
       "<g id=\"node3\" class=\"node\"><title>W</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"252.944\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"252.944\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">W</text>\n",
       "</g>\n",
       "<!-- W&#45;&gt;gradients/MatMul_grad/MatMul -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>W&#45;&gt;gradients/MatMul_grad/MatMul</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M241.404,-73.4647C235.016,-64.8665 226.922,-53.9704 219.654,-44.187\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"222.317,-41.9021 213.544,-35.9618 216.698,-46.0764 222.317,-41.9021\"/>\n",
       "</g>\n",
       "<!-- gradients/Shape -->\n",
       "<g id=\"node4\" class=\"node\"><title>gradients/Shape</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"66.9441\" cy=\"-162\" rx=\"66.8882\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"66.9441\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">gradients/Shape</text>\n",
       "</g>\n",
       "<!-- gradients/Shape&#45;&gt;gradients/Fill -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>gradients/Shape&#45;&gt;gradients/Fill</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M86.6139,-144.411C97.4419,-135.279 111.042,-123.809 122.86,-113.842\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.314,-116.351 130.702,-107.228 120.801,-111 125.314,-116.351\"/>\n",
       "</g>\n",
       "<!-- gradients/grad_ys_0 -->\n",
       "<g id=\"node5\" class=\"node\"><title>gradients/grad_ys_0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"233.944\" cy=\"-162\" rx=\"81.7856\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"233.944\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">gradients/grad_ys_0</text>\n",
       "</g>\n",
       "<!-- gradients/grad_ys_0&#45;&gt;gradients/Fill -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>gradients/grad_ys_0&#45;&gt;gradients/Fill</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M214.037,-144.411C203,-135.213 189.117,-123.644 177.096,-113.627\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"179.053,-110.701 169.13,-106.988 174.571,-116.079 179.053,-110.701\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<workshop_utils.TensorflowGraphToDot at 0x7f1116ed6d68>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_derivative_symbol = tf.gradients(y_symbol, x_symbol)\n",
    "TensorflowGraphToDot(partial_derivative_symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.Session`\n",
    "\n",
    "A `tf.Graph` can be executed on different devices (CPUs, GPUs, Distributed, ...).\n",
    "Due to the graph structure you can also easily run different parts of the graph on different devices.\n",
    "The `tf.Session` object is responsible for executing your graph accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = tf.InteractiveSession()\n",
    "session.list_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can execute a (part of a) graph by calling the **run** method of `tf.Session` with the `tf.Operation` (node of the graph) you want to calculate as the argument. This is the first time we actually calculate something in tensorflow! We get the same result as with our numpy code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40., 46.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(y_symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.placeholder`\n",
    "\n",
    "Instead of assigning to each symbol explicit values, we can put in some placeholders.\n",
    "So we only have to define our graph once, and afterwards we can use it for many different inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"134pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 134.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 130,-112 130,4 -4,4\"/>\n",
       "<!-- MatMul_1 -->\n",
       "<g id=\"node1\" class=\"node\"><title>MatMul_1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"49.2915\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">MatMul_1</text>\n",
       "</g>\n",
       "<!-- x_1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>x_1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">x_1</text>\n",
       "</g>\n",
       "<!-- x_1&#45;&gt;MatMul_1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>x_1&#45;&gt;MatMul_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.3496,-72.7646C39.5428,-64.6113 44.7279,-54.5291 49.4709,-45.3066\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"52.7324,-46.6176 54.1934,-36.1239 46.5074,-43.4161 52.7324,-46.6176\"/>\n",
       "</g>\n",
       "<!-- W -->\n",
       "<g id=\"node3\" class=\"node\"><title>W</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">W</text>\n",
       "</g>\n",
       "<!-- W&#45;&gt;MatMul_1 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>W&#45;&gt;MatMul_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.6504,-72.7646C86.4572,-64.6113 81.2721,-54.5291 76.5291,-45.3066\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.4926,-43.4161 71.8066,-36.1239 73.2676,-46.6176 79.4926,-43.4161\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<workshop_utils.TensorflowGraphToDot at 0x7f1116bddba8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_placeholder = tf.placeholder(dtype=tf.float64, shape=[1, 3], name='x')\n",
    "y_symbol = tf.matmul(x_placeholder, W_symbol)\n",
    "TensorflowGraphToDot(y_symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before executing the path, the placeholder is replaced by the value provided by the feed_dict argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40., 46.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(y_symbol, feed_dict={x_placeholder: x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Processing\n",
    "\n",
    "Instead of doing just one calculation, we can simultaneously do a whole **batch** of calculations.\n",
    "Note that we leave the first dimension of our placeholder unspecified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 40.,  46.],\n",
       "       [ 94., 109.],\n",
       "       [140., 163.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0],\n",
    "    [7.0, 8.0, 8.0],\n",
    "])\n",
    "\n",
    "x_placeholder = tf.placeholder(dtype=tf.float64, shape=[None, 3], name='x')\n",
    "y_symbol = tf.matmul(x_placeholder, W_symbol)\n",
    "session.run(y_symbol, feed_dict={x_placeholder: x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Exercise</h3>\n",
    "Modify the above code to calculate:\n",
    "\n",
    "$$ y = \\tanh(W \\cdot x + b) $$\n",
    "\n",
    "Execute the calculation with numpy and with tensorflow.\n",
    "\n",
    "<h3>Question</h3>\n",
    "Take a look at the partial derivative $\\frac{\\partial y}{\\partial x}$.\n",
    "Why does tensorflow still calculates the $\\tanh$ term and not the derivative?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Details\n",
    "\n",
    "We won't go into further details here and instead focus on our first machine learning application.\n",
    "For more information on the `tf.Graph` and `tf.Session` I refer you to:\n",
    " \n",
    "https://www.tensorflow.org/programmers_guide/graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "\n",
    "The MNIST database (Modified National Institute of Standards and Technology database) is a **dataset**\n",
    "containing 60K training and 10K test images showing hadwritten digits with a resolution of 28x28.\n",
    "Predicting the digit shown in each image is the \"hello world\" task of machine learning.\n",
    "\n",
    "Tensorflow contains a convenience function, which automatically downloads and reads in the entire dataset.\n",
    "The training dataset is further split into a 55K training and 5K validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Exercise</h3>\n",
    "Familiarize yourself with the dataset by executing the next line of code several times\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff6ac489fd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6bf351588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "i = np.random.choice(55000)\n",
    "plt.title(mnist.train.labels[i].argmax())\n",
    "plt.imshow(mnist.train.images[i].reshape(28,28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model\n",
    "\n",
    "In machine learning it is best practise to start with the simplest model to establish the overall procedure.\n",
    "\n",
    "We implement a linear model $f$ with weights $W$:\n",
    "$$ f: R^{784} \\rightarrow [0, 1]^{10}$$\n",
    "\n",
    "$$ f(\\vec{x}) = \\underbrace{\\frac{\\exp \\vec{l}}{\\sum_{i=1}^{10} \\exp l_i}}_{\\mathrm{softmax}(l)} \\quad \\quad \\textrm{where} \\quad \\vec{l} = W \\cdot \\vec{x}$$\n",
    "\n",
    "Here we encounter a new concept in tensorflow: a `tf.Variable`. `tf.Variable`s are (of course) tensors which can be adjusted by operations. All free (learnable) parameters of your model are represented by a `tf.Variable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "logits = tf.matmul(x, W)\n",
    "probabilities = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss-function\n",
    "\n",
    "For **multi-class classification** one usually wants to minimize the **cross-entropy**.\n",
    "\n",
    "$$ H(y,p) = - \\sum_{i=1}^{10} y_i \\log p_i $$\n",
    "\n",
    "Keep in mind that we always operate on a batch of images (for instance $N = 100$ images per minimization-step).\n",
    "Therefore our loss-function is the average cross-entropy.\n",
    "$$ \\mathcal{L} = \\frac{1}{N} \\sum_{j=1}^{N} H(y_j,p_j) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(y * tf.log(probabilities + 0.001), axis=[1])\n",
    "loss_function = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "We use a simple gradient-descent optimizer.\n",
    "\n",
    "$$ \\Delta W = - \\eta \\frac{\\partial \\mathcal{L}}{\\partial W} \\quad \\quad \\textrm{where} \\quad \\eta = 0.5 $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize = tf.train.GradientDescentOptimizer(0.5).minimize(loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Training in tensorflow means just running the **minimize** operation multiple times, here we run 1000 minimization steps. In each step we process a batch of 100 images, and adjusts the weights to minimize the mean cross-entropy of the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    session.run(minimize, feed_dict={x: batch_xs, y: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Evaluation\n",
    "\n",
    "Finally we evaluate the linear model. We are interested in the **misclassification rate** of our model.\n",
    "We evaluate the misclassification rate on the entire train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.08550906\n",
      "Test  0.08469999\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(probabilities, 1), tf.argmax(y, 1))\n",
    "misclassification_rate = 1.0 - tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Train\", session.run(misclassification_rate, feed_dict={x: mnist.train.images, y: mnist.train.labels}))\n",
    "print(\"Test \", session.run(misclassification_rate, feed_dict={x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Exercise</h3>\n",
    "Add a bias $\\vec{b}$ to the linear model\n",
    "\n",
    "$$ f(\\vec{x}) = \\underbrace{\\frac{\\exp \\vec{l}}{\\sum_{i=1}^{10} \\exp l_i}}_{\\mathrm{softmax}(l)} \\quad \\quad \\textrm{where} \\quad \\vec{l} = W \\cdot \\vec{x} + \\vec{b}$$\n",
    "\n",
    "<h3>Question</h3>\n",
    "What is the purpose of the bias?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow Neural Network\n",
    "\n",
    "We established a baseline model. Next, we train our first neural network with tensorflow using the low-level API.\n",
    "There are predefined convenience function for most\n",
    "In machine learning it is best practise to start with the simplest model to establish the overall procedure.\n",
    "\n",
    "We implement a neural network model $f$ with learnable weights $W_h$ and $W_o$ and biases $\\vec{b}_h$ and $\\vec{b}_o$:\n",
    "\n",
    "$$ f: R^{784} \\rightarrow [0, 1]^{10}$$\n",
    "\n",
    "$$ f(\\vec{x}) = \\underbrace{\\frac{\\exp \\vec{l}}{\\sum_{i=1}^{10} \\exp l_i}}_{\\mathrm{softmax}(l)} \\quad \\quad \\textrm{where} \\quad \\vec{l} = W_o \\cdot \\tanh \\left(W_h \\cdot \\vec{x} + \\vec{b}_h \\right) + \\vec{b}_o$$\n",
    "\n",
    "Note that we initialize the weights with random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "W_h = tf.Variable(tf.random_normal([784, 20]))\n",
    "b_h = tf.Variable(tf.zeros([20]))\n",
    "hidden_activation = tf.tanh(tf.matmul(x, W_h) + b_h)\n",
    "\n",
    "W_o = tf.Variable(tf.random_normal([20, 10]))\n",
    "b_o = tf.Variable(tf.zeros([10]))\n",
    "logits = tf.matmul(hidden_activation, W_o) + b_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss-function\n",
    "\n",
    "Instead of calculating softmax and the cross-entropy ourselves, we use the `tf.nn.softmax_cross_entropy_with_logits_v2` function for this:\n",
    "  1. The naiv softmax-cross-entropy implementation is numerically unstable if a probability is 0\n",
    "  2. The native tensorflow function is optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize = tf.train.GradientDescentOptimizer(0.5).minimize(loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for i in range(10000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    session.run(minimize, feed_dict={x: batch_xs, y: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.07289094\n",
      "Test  0.083599985\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "misclassification_rate = 1.0 - tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Train\", session.run(misclassification_rate, feed_dict={x: mnist.train.images, y: mnist.train.labels}))\n",
    "print(\"Test \", session.run(misclassification_rate, feed_dict={x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Exercise</h3>\n",
    "Add an additional hidden layer to the model\n",
    "\n",
    "$$ f(\\vec{x}) = \\underbrace{\\frac{\\exp \\vec{l}}{\\sum_{i=1}^{10} \\exp l_i}}_{\\mathrm{softmax}(l)} \\quad \\quad \\textrm{where} \\quad \\vec{l} = W_o \\cdot \\tanh \\left(W_{h_2} \\cdot \\tanh \\left(W_{h_1} \\cdot \\vec{x} + \\vec{b}_{h_1} \\right) \\vec{b}_{h_2} \\right) + \\vec{b}_o$$\n",
    "\n",
    "<h3>Question</h3>\n",
    "Why do we need to initialize the weights with random numbers?\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
